It's basically just a really, really fancy and pretty neat predictive keyboard with a lot of math"
"It's important to note here, and note repeatedly as the dialogue evolves, that ChatGPT *doesn't actually understand anything*. Even criticizing it as misunderstanding high-level concepts is a fundamental mistake in characterizing what it's doing and how it's generating output. It ""misunderstands"" things because it can't understand things in the first place. It has no coherent internal model of the world. It's a Chinese room with a pretty darn good dictionary that nevertheless has no way to check whether its dictionary is accurate."
"I think this is the key difference here between AI and a person. chat GPT is just a really fancy box that tries to guess what the next letter should be given a string of input. it doesn't do anything more, or anything less. this means that it's much more of a evolution of older Markov chain bots that I've used on chat services for over a decade now rather than something groundbreakingly new. it's definitely way better and has more applications, but it doesn't understand anything at all which is why you can tell on more technical subjects that it doesn't understand what it's actually doing. it's just spewing out word soup and allowing us to attach meaning to the word soup."
"Yep, can confirm, can't speak for other fields but from my experience of playing around with ChatGPT it is not very good at conveying the nuances of a research paper that it summarized when you begin to ask slightly specific questions about the paper's content.

