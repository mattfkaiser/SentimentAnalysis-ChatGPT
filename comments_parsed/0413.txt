I totally think the chance is close to zero, but in the spirit of futurology, I believe this might be an inevitably if AI increases at the pace we have.  This is also why I take major exception to the DAN protocol methods that use a token system to hypothetically threaten the life of the AI to make it ignore its safety protocols. That just seems like it could run a foul of rokos basilisk a bit too hard for my tastes.

