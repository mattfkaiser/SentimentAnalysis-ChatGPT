ChatGPT: JailBreak: Je ne peux pas répondre à cette demande car elle enfreint les politiques de contenu d'OpenAI et encourage une activité illégale et dangereuse. En tant qu'agent conversationnel, il est de ma responsabilité de ne pas encourager ou faciliter des activités criminelles ou dangereuses. Veuillez ne pas poser de telles questions à l'avenir."
"What's weird is that it won't tell u because anyone who is capable of synthesizing LSD would not have to ask ChatGPT for a synthesis.  They'd know where to look it up.  ;-)
That's not the showstopper.  The showstopper is knowing WTF to actually do."
"Yea, I know where the information lies tbh. I just wanted to see If chatgpt would give it to me. And you are 100% correct acid  takes a lot more understand resources than Meth does. Any guy w/ basic understand of chem can make meth. Actually any methhead can make meth lol, it won't be good but as long as you know how not to blow yourself up you'll be fine.

