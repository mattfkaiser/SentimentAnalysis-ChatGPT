For it to be factually correct, you need in theory be 100% certain that the data you're feeding it is 100% factually correct. With the amounts of data they're feeding ChatGPT, you can't be certain. Even in this study it's ""randomly selected"" online responses. And then when it makes mistakes it's hard to pinpoint why, because there's so much data. And even if *in theory* you were certain that it was 100% factually correct in regards to the subject, the data is still written by humans. Portions of the data *will* have biases, and will not be relevant to every human on the planet, because some populations don't have as much online data as others."
"Let's try setting ChatGPT loose on insurance sellers and see if there's an actual use case worth using here. If it can win more fights faster than human physicians can win, that's a legitimate use case."
"Yeah what's the point of this study? Chatgpt is never going to respond in a rude way, so any docs on reddit responding in such a way already are going to drag the human average down wrt empathy. Also, on askdocs, frequently the first responses you'll get will be probing for more information, and they tend to be short questions. I doubt chatgpt did that at all."
"The friendliness and niceties that service workers give you when you are at restaurants, movie theaters, grocery stores, etc... (usually) aren't genuine. The highschooler giving you a ticket at a movie theater does not care if you enjoy your movie, they say it because they are supposed to.

