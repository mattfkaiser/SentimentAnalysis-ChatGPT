I don't know why you're making excuses for this person, they're not saying that it's "possible moderator messaging", they're literally claiming that they "can always tell when the AI has been taken over by human response". Then they claim that the AI have been taken over after being provided with what seem to be quite factual statements about the most recent US presidencies. The user clearly disagrees with...reality, basically, and while I can't claim to know what exactly in the AI response set them off I am seeing a certain very recognizable subtext present in certain types of political leanings. The questions about racism, the style of typing, and odd personal insults just cement my assumptions.

The user clearly lacks understanding of how the ChatGPT works, and when confronted with this, defaulted to questions to about politics and racism, and a very specific type of racism about specific races as well as a very specific common political question. I obviously cannot say that the user is racist just based off what they posted, but they're clearly trying to see if ChatGPT is biased in a certain ideological way and are angry due to their perception that ChatGPT is indeed biased in that manner.

I am also willing to give OpenAI the benefit of the doubt and assume that they have obvious reasons as to why they first put up the filter regarding racism for black people before putting up a filter for white people. They're clearly tuning these filters over time in response to user input, and as such they've probably seen a large amount of questionable user input of a certain type that they need to specifically filter out.