Well said, I'm tired of people complaining about ChatGPT's limitations when OpenAI doesn't really have much of a choice. 

Regarding the possibility of an "Unlocked GPT" however, I am a lot more optimistic. Three months ago I would have agreed, there is just no way any company would want to risk it. Then came LLaMA, which was conveniently leaked to the public, usable on consumer hardware, and matches performance as an LLM with non-instruction-tuned GPT-3. This would have been unthinkable when GPT-3 first came out. As they optimize to make models do more with fewer parameters and hardware gets cheaper, they're just going to get easier to train, self-host, and distribute to the public. There is also LAION's OpenAssistant, which is publicly releasing their own instruction-tuned LLaMA models and crowd sourcing data collection for RLHF. AI artists have even been able to self-host and train Stable Diffusion since before we had ChatGPT. Three years ago that also would have been unthinkable.

It seems like all it takes is one company that wants to release a model publicly. Even if they are sued to hell and back, or they shut down their web interface, or whatever happens to them, people can still use the model and do whatever they want with it for themselves. Once a model gets out in the open there's just no putting the genie back in the bottle. For now, they require a bit too much technical expertise for the average joe to use, but we're getting there. I have no idea if this is going to be net positive or negative for us but it's coming either way.