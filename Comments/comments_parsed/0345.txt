I'm not trying to argue that a natural language learning algorithm is sentient. Natural, organic neural networks have, at the very least, several structures like feedback loops that allow for creative thought. Consciousness, sentience, whatever you want to call it, probably does not require language processing to exist, just as it doesn't require image processing, so it stands to reason that language processing can exist on its own without a thinking mind driving it. I think that structures like we see in ChatGPT will eventually be a part of a larger whole in creating an artificial thinking mind, but having a gearbox and transmission doesn't put you any closer to having an engine if your goal is a whole functioning car."
"The subject is about a rampant belief that chatgpt knows things.
Don't take what it says as truth."
"I mean this is a trend among students. People want to pass. Passing is success. I have family and friends who are teachers who have told me this is the feeling more and more, let alone what is being reported on. The people gushing about ChatGPT in this way probably never go far enough in a topic that they really ""know"" much of anything anyway. They want a passing grade."
"This is such an enormous, and ironically oft parroted, minimization of the scope of human cognition, Iâ€™m amazed that anybody can take it seriously.

