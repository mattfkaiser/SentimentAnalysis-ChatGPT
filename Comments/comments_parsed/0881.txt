1. `evaluators did not assess the chatbot responses for accuracy or fabricated information` -> ChatGPT is just generating text based on probability of words appearing together. It does this in a fancy way so the generated text looks really good, but the inherent limitation of this model is that it might generate complete nonsense of falsehood. So in this particular case you might get high-quality empathetic response... which is also completely wrong.
2. Second issue comes from the technical side -> ChatGPT needs data to learn from (to derive the probabilities). This means for example that if people start using ChatGPT more and write less on /r/AskDocs then ChatGPT will be worse and worse at answering more recent questions, because it won't have data to learn from."
"Eh. My husband frequents reddit after work. Reddit isn't the greatest place to go for empathy, in general drs around here trying to answer the question asked as directly as possible. It's hard to gauge the sincerity and connect in the normal way they would get to in thier office via the web. Chatgpt is actually not the greatest when it comes to medical advice. It's great when it comes to making a natural sounding easy to understand answer, but isn't exactly perfect and often gives inappropriate medical advice (if you force it)"
"This is interesting, especially since the article points out that ChatGPT covers more angles of concern for the patient.

