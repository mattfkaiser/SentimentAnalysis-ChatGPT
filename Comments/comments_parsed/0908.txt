The commenter above is obviously simplifying it a great deal. But saying that ChatGPT has an ""understanding"" of something is misleading. It is not a thinking and reasoning machine. It is a machine-learning driven language model trained on insane amounts of data. A language model is a probabilistic way of stringing words together, a computation of language. Put very simply, ChatGPT strings together words in what it *calculates* is the most ""correct"" way based on it's dataset. Meaning it cannot have an  ""understanding"" of what it's talking about, it's just trained on so so much data that it looks very natural and often is correct.

