It does not ""copy"" text directly. It generates text. And as I mentioned, it's very natural sounding, because the amounts of data it is trained on is insane. It's not as simple as you or the person above are putting it."
"I'm definitely not arguing semantics. You said ChatGPT can ""understand"" concepts and hypotheticals. You used  the word very concretely. In the *commonly used* sense of the word, however ""ill-defined"" the concept is, it is misrepresenting ChatGPT as something that can think and reason. I doubt you think ""understanding"" something means ""stringing the right words together"", because humans can definitely understand concepts without knowing the words to describe them. ChatGPT cannot do that. It has a dataset of words, and it knows what words *could* come next, and then it calculates which one. Do you see the difference?

