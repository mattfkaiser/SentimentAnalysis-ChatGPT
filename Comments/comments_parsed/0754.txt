But let's take two steps back here. LLMs are recognizing patterns in their input. There is nothing preventing it from finding patterns that align with some mathematical concepts. For example the multiplication table for 11 has a very obvious pattern: 22, 33, 44... An LLM could absolutely cotton on to this. And eventually even make fairly practical application of it. Combine this with other patterns it finds, and an LLM can start getting basic math problems correct a decent portion of the time. But it is not operating like a calculator behind the scenes. It is doing math in a fashion far more similar to how we humans do it, and as a result it still makes mistakes. This becomes pretty obvious when you ask it enough questions. And there is no shortage of articles and videos demonstrating Chat GPT4 failing at math. But it has gotten better, no doubt."
"The issue with ChatGPT is that it has its own style. All you have to do is feed ChatGPT examples of your written work, and then ask it to write a new paper using the same voice and writing style, including the same spelling errors, grammatical errors, and punctuation errors as your example papers. The result is something new that is nearly indistinguishable from something that would have written."
"I am working my masters right now and one of my professors has us USING chatgpt as part of our writing process. We have to submit our work with our papers showing how we are manipulating the AI to write for us. It's like doing math homework where you have to prove how you got to the answer. Now it's proving how we are writing and doing research. Interestingly each of my peers are getting slightly different outcomes based on how we are interacting with it even with work that we are answer the same question with.

