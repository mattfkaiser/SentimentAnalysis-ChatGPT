A guess. Chat GPT is likely several models strung together. It probably has a model which determines the request type. The the request is routed to the proper model. The model that does summarization of text is different then the one that builds code. There were already models in existence that exhibited chat functionality and Q&A capabilities. This is just a breakthrough in fidelity.

As far as "understanding". AI is basically a giant network of weighted associations. Each word is a token that is associated with other words. For example the order in which words are usually typed is an association. Nouns from the same topic and appear together like "computer" and "wifi" is also an association. You build models using engineered dataset to do specific tasks. For example technically Q&A and summarization of text would be considered two different tasks. Early model development would focus on one task. Open AI found a way to daisy chain these processes together.

I would not say that the model does not "understand". It does to a degree understand. But that understanding is incomplete. When I see the word dog. I know how it feels, what it sounds like, what it's looks like, the emotions associated with the interactions. An AI algorithm may know what it looks like in 2D and find a description but it doesn't know all the other stuff. This is not to say AI are sentient. They are mathematical/mechanical processes meant to emulate certain aspects of cognition.