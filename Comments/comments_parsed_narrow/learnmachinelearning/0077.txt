I think there exists an exaggerated opinion against ChatGPT's factual mistakes. It is obviously highly dependent on the kind of question you ask it. If you ask it something too specific, or deliberately frame the question in a convoluted way, it will certainly misfire.  

In my experience, ChatGPT is best used to smoothen the initial learning experience to something new for you. For example, I will ask it the stupidest questions I can think of when I start learning a new programming language. I will ask it to draw a comparison with a language I already know. I will also ask it to debug the "obvious" errors or ask it how I can do something that would be "obvious" to a semi proficient person in that domain. ChatGPT doesn't falter here. It can understand your question very well( it's a great query parser) and let you know in simple terms the bare minimum about a topic you have no idea at all.

Another example where I find using ChatGPT effective, is to simply ask a programming documentation specific implementation detail about some commonly used library. Say I have some specific question about how boto3 (AWS python SDK) client for an AWS service behaves under specific conditions. ChatGPT will more than likely get you the correct information instead of you having to skim through the documentation to find stuff relevant to you. And even if the info is incorrect or partially correct, you will get quick feedback on whether it works or not, allowing you to move to your next question or reframe the existing one

I see ChatGPT as an immense productivity enhancer as it gets you the information you need much quicker and with lesser effort compared to Google search etc.