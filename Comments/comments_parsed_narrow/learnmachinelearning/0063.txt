Why don’t you read the prompt once more and figure out his intention instead. 

He did mention training on his own dataset didn’t he? And his first sentence even hinted he was having the impression it could be done locally when the public API was available. My best guess of his fine tuning was more about updating the existing parameters of chatGPT using his dataset - aka retraining. I tried to clarify such idea might not be attainable. I left my comment with some ambiguity was because even if you cannot update the base parameters, but you can still “fine tune” it by locking up parts of the context vector or they would allow your corpus to feed into some encoder to get some latent variables, and concat the prompt with the latent variables into the model. Or what if they later release a lite offline version with trimmed down parameters and with APIs that allow you to actually update some parameters. This is particularly appealing to enterprises with private cloud infrastructures. The possibility is just wide open. Who knows, do you know enough about ChatGPT and OpenAI?