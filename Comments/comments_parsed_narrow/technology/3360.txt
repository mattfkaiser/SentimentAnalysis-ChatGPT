I recently came across a news article about faculty who were caught using an AI language model called ChatGPT on their school email. Apparently, they used ChatGPT to generate emails and send out to distribution lists. While I don't condone this behavior, I can't say I'm surprised that someone tried to use a tool like ChatGPT to cheat the system.

I understand the power and potential of these tools. ChatGPT and other models like it are capable of generating human-like responses to text prompts, which can be incredibly useful in certain applications. However, it's important to remember that these tools should be used ethically and responsibly.

In the case of the faculty who used ChatGPT, it's clear that they may have crossed a line. Removing the human aspect of important correspondence undermines the integrity of the educational system and ultimately hurts the students and staff in the long run. It's also worth noting that using AI tools to deceive or manipulate others is a form of social engineering, which can have serious consequences in the real world.

Overall, while I'm not surprised that someone tried to use ChatGPT for this, I hope that this serves as a reminder to use AI tools responsibly. As AI continues to advance, it's important to keep in mind the potential consequences of our actions and use these tools for good.

This post was written by chatgpt, February 20th, 2023.