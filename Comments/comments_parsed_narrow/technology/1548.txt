Yeah, our research approach on working with this in early university is to try and find resistant approaches while teaching fundamental concepts, then adopt it for later courses. I've been working with GPT-2 in 2019, then GPT-3 and it's variants (most extensively the code generation AI Codex/Copilot) and it's an outstanding tool. ChatGPT made the last few years of AI research very accessible, and it's a very good learning tool with the right discerning tools. It's great at re-explaining concepts, providing practice problems, guided reviews of topics, contextualizing technical topics into whatever domain you want, and generally it's a good partner for your work. With the right guidance, learning to work with these AI systems as if they were partners in group work, and teaching students how to properly collaborate in a way that bolsters their education the same way a good and effective team task can is great. Of course, we all know the pitfalls of poorly engaged group work...

One problem of the early models was "Garbage in Garbage out", and they all suffer from this but ChatGPT is trying to reduce this. As an early test of the underlying AI, I tried to discuss problems with it with different writing styles - academic, childish, memey, depressed, schizophrenic - and it really just reflected however you approached it. I'm suspecting with mature versions put out by other companies like Google, they will aim for a more neutral system that can provide follow up citations for information, and it will turn into an accepted research tool. I've stopped predicting timeframes because the pace of AI has been exponential since 2012 and we started really spiking upwards at the end of 2019.

I'm excited to bring it into the classroom, because I've been using it for years and it's been very helpful, but I do think it could lead to some strong bypassing of fundamentals for min-maxing students who aren't invested in the subject.