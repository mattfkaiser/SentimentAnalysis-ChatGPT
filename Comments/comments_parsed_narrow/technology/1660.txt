To build upon your point. I have had multiple exchanges with ChatGPT about what it does and does not find appropriate. In many cases the programme seems to promote traditionally western ideals of morality and culture. Being a researcher in diversity and inclusion specifically around cultural identity for almost 5 years, I can’t help but feel that ChatGPT is a concerning example of ethnocentrism. A classic line that I have heard from the programme is “this isn’t acceptable regardless of the cultural context” while exploring the limitations of what GPT thinks is moral and immoral. 

One of the ways I’ve actually set out to explore GPT’s ethnocentric interpretation of morality is by prompting it with scenarios and storylines from Star Trek; since the show largely revolves around fictional multicultural and cross cultural interactions. Another reason why Star Trek is a good example is because the stories are fictional and do involve intelligent life forms that are distinct from a human evolution of culture and morality. In many cases when prompted with these scenarios, when Chat GPT does flag something as inappropriate it often involves the alien culture; or the cultural Other. Rather than accepting that there are differing cultural and evolutionary perspectives on morality and arbitrary measures such as inappropriateness, the AI is inclined to say certain scenarios are “inappropriate regardless of cultural context”. And when confronted with the argument that there is no universality of ethics the programme often says “while there is no universality of ethics, X is inappropriate regardless of the cultural context.” Similar issues when I run these experiments giving scenarios of cross-cultural exchanges across real people and cultures.

One possible reason why this might be is because the developer Open AI is actively promoting western idealism, especially when it comes to culture and ethics, due to their own implicit bias (probably the most likely) or it could be a more explicit bias in an attempt to promote more western centric values and ideas (probably unlikely), or it be some mixture of both. The other issue could be the datasets themselves, primarily being written in English, lack any real diversity and inclusion based on the lived experiences of groups and people traditionally not included within the broad interpretation of Westen white cis-male heterosexual dominated culture. Both of these are clearly significant problems that should be worked on and improved. However, with that being said, chat GPT does seem to be a better attempt at developing an ethical language model processing AI, albeit it is flawed. I am hoping that as development continues these issues can be addressed to improve diversity and inclusion.