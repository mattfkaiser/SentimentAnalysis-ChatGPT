The problem lies in interpretation. You just gave a perfect example of that. It does make stuff up, just not in the way humans understand it. I can guarantee you from personal experience that ChatGPT fabricates sources and even draws conclusions from inadequate information. This is perfectly in line with what you just pasted. It GENERATES responses based on …. . Generates is the key word here. 

While the program itself is amazing, the danger lies in the interpretation and what can be done with it. You can have it write your essays, but it will never ‘understand’ what it is writing.