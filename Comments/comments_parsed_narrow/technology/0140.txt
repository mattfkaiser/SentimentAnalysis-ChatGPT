As a computer scientist, the number of people trusting ChatGPT's answers is fucking astounding. It's a great tool for what it is, but it's not really programmed to tell you when it doesn't know something. If you ask it a question, it will almost always answer in the affirmative unless you hit its content filter. It's pretty easy to see through if you ask it very specific questions about a subject you're well versed it.