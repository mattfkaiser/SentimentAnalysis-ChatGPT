This is literally an example of ChatGPT making stuff up. Because that last paragraph is not an accurate representation of output. It's not only unexpected or unusual, some of it is just plain wrong.

Also, you can't use a system to validate the truthfulness of that system. "We investigated ourselves and found nothing wrong" is the idea you want to remember.