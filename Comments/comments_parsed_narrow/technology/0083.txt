This has nothing to do with ChatGPT being trained on untrue training data containing made up stuff. It is just an artifact of how the technology works. Look up "hallucination language model".

https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)