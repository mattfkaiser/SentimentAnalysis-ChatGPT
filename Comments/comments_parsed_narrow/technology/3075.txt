I teach HS science in a private school (read, small classes), so this doesn't affect me as much as some of my peers. We are currently evaluating our position on the tech and how to use/regulate it. The basic gist I'm getting is that it's pretty easy for our English teachers to get a sense of writing style and immediately notice Chatbot output as not normal. Also, it isn't great at any kind of deep analysis. The big tool in our belt is that we use Google Docs for almost all writing. That means it is a simple matter to look at revision histories. That would very quickly and easily tell you whether the student used an AI or not. Those histories are really messy.

The biggest issue I have found is that ChatGPT lies like crazy. I asked it about finding articles with citations that looked at risks to teens from creatine use. It dutifully cranked out the arguments (which were valid) and three sources. Every single one was falsified. The journals were real, but no such article or author existed in the database. 

We're leaning towards a policy of it's completely off limits unless your teacher approves it for a specific purpose.  We have been discussing that there may be scenarios where it is a great tool to use for a project, but these are probably the exception, not the rule.