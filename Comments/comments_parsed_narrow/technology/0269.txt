It goes both ways. Whenever you see a comment that says something like "ChatGPT is a language model. All it's doing is predicting the next word. It isn't capable of reasoning or understanding anything." it betrays not only a lack of understanding of what the model is actually doing under the hood (while pretending to understand) but a lack of understanding of, well, words, thinking, reasoning, comprehension, the lot of it. The person making this sort of comment doesn't have a surface understanding of the topic. They got that phrasing from *someone else's surface understanding*. It's borderline copypasta that rings hollow when it comes from random person #27473828

Meanwhile the freaking chief scientist of OpenAI is [out here saying this.](https://twitter.com/bio_bootloader/status/1640512444958396416?t=QDdshoYvxsh7qObo6xPTyQ&s=19) 

Truth is, there are very very *very* few people who actually know what the hell is going on right now. And there is so much information out there that you can find sources to back up almost any belief you decide that you want to have. And people *love* to talk and parrot information when they quite simply do not know shit. Tread carefully.