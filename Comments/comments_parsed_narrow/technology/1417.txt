The *factual* errors can be high, but the natural language generation is strong enough to be a useful aid to a wide variety of communication goals.

ChatGPT is already pretty damn reliable at doing what it aims to do: generate coherent, natural-sounding text. Your contempt for its ability to provide factual information is just you judging it on something it doesn't even claim to be for, which is fundamentally the same error being made by the lawyer.