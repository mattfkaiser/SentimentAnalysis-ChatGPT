One could argue such fictional scenarios cause real harm - as evidenced by Donald Trump and other Republicans creating a similar fictional scenario leading to the events of January 6th. Or a fake story about a drag show damaging children being aired as truth on Fox News or even worse far right "news" shows.

There are good reasons to prevent something like chatgpt from being able to churn out fake stories that could be parroted as truth and cause real harm. Naturally, one can argue about the idea that whoever controls the AI controls the narrative, and that is also a valid concern. But the examples posted up thread have already been shown to cause real harm even when they are fiction and/or lies.