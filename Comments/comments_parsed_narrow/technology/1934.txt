I'm not an expert at all on AI, so this may sound naive. I did study political misinformation in grad school prior to the topic itself becoming politicized. I never really had an adequate solution to the problem of misinformation other than the Internet needs to include better tools for users to assess what they're reading which again was beyond my abilities. 

My main question was this and Chat GPT makes it all the more relevant: Is there no way we could include certain measures like thruthiness, bias, and the rate that the info may be outdated (for topics that are quickly evolving), the potential to elicit emotions, etc? Not only in generating responses but as tools to evaluate news articles, or any type of information online. The measures need not be perfect but would allow for someone a way to assess the veracity of the information.

For Chat GPT, it would allow for greater tooling of the response. Say you are writing a factual piece, you would want to keep that as high as possible. Say you're trying to write a strong persuasive piece you would keep the emotion provoking measure high. This of course would allow for propaganda to circulate more easily which is already going to be a problem but if the tool itself accounts for it and the measures are readily available everytime we read anything - human or Chat GPT generated then we would at least have something to keep us grounded.