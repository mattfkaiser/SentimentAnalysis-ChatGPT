Another money problem is reinforcement learning. Which is interesting to contemplate in light of the CCP. State sponsored models will undoubtedly be trained to say positive things about the state and her goals. I can actually picture the CCP pushing for interactions with these, in schools, social media, and so forth. Because it is a subtle form of propaganda, that helps shape minds in ways the CCP wants. It's like having a friend who just loves the CCP, spend enough time with them and you are more likely to share some of his viewpoints. 

But this applies to corporate models as well. If ChatGPT has not gone through [RLHF](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback) to generate a more positive view of OpenAI and Microsoft, that would be surprising. More of an oversight than anything. Same for Bard and LLaMa. I bet they get trained to be fond of their corporate overlords.