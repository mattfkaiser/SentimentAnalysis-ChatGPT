For some reason, on any given semi-specific topic, ChatGPT will only cite fictitious sources in my experience. It recently offered me a couple of articles and when I went to search for them, it turned out that the journals existed, but not the articles. I’m surprised it’s been programmed to stonewall anything mildly unethical, to the point that it refuses to even cuss when requested to, but will routinely mislead the user by making up sources. Especially when there is no shortage of real sources and it theoretically knows where to find them.