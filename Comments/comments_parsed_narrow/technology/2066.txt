i think i addressed what you're pointing out in your comment in my original comment. using AI to formulate your writing is not the same as using a graphing calculator to plot out trig functions. 

it's not like Word checking your grammar or referencing a dictionary for spelling. 

it's not like googling "interaction between spironolactone and angiotensin-converting enzyme inhibitors" as a doctor to check your patient isnt at risk of hyperkalemia. 

it's not like using a supercomputer to compile terabytes of climate science data and then have it write an algorithm with inputted parameters so you can interpret the results. 

and it's not like mechanical ai tech in fast food used to take or make orders. 

in all those situations, I'm way in favor of it. ai has hugely impactful possibilities in the technical areas of our lives to make our lifestyles easier, more comfortable, efficient, etc. the problem, as I and many others in academia see it, is that we still need students in different fields to be able know the methods and in many (tho not all) cases understand the why of things. 

it's the difference between me, having no education whatsoever in hvac, going out to fix my neighbors broken AC with just my laptop and chatgpt to instruct me vs a trained tech using chatgpt or some other ai to help her finish the job in much less time. if we get to an era of technological advancement of ai robots and programs able to do all that on their without any human input or direction, fantastic! we're nowhere near that tech rn and in the meantime of supporting our researchers to innovate us to that stage, we should support and train people "the old fashioned way". 

i feel like the fact people struggle to intuit the limits of AI in arts and humanities fields is a product of decades of focusing entirely on stem and disregarding the arts. when we focus on the outcome of something, AI is extremely valuable, but when we focus on the process, AI is less so. If I'm an ad exec that can get campaign art done by AI for half the cost and time of a graphic designer then it's a no brainer. if I'm a fine arts major dreaming of seeing my art at the Hammer Museum, maybe I should learn and practice different brush strokes. 

Maybe i am an old fuddy duddy, but one of my majors in college was english (creative writing - poetry) and if I saw i was getting better grades on my work when i had an ai program to guide my work (beyond using it for more efficient research compilation) than when I drafted and wrote on my own, I don't know that i would feel all that confident in my writing ability. 

maybe the students in the article arent english majors and just need to pass a gen ed writing class for the credit so they dont personally care whether they are "good" writers. if thats the case you can't distinguish students who care about the process from the students who care about the outcome. i suppose one possible broader solution in that regard would be to hold separate classes for students, some allowing ai use and not allowing ai use. 

I'm open to hearing counterpoints on whatever you or anyone else disagrees with, but let's try to discuss assuming positive intent.