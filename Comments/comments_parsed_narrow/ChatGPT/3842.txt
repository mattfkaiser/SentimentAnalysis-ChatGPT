Inventing something requires holding on to a lot of information and seeing relationships among that information. Current ChatGPT didn't have a large enough context window to handle much invention.

If you could assume an infinite context window, what you would be doing is to continue training the model albeit slowly if it was relying on human input for the step of training where it compares its calculation with the ground truth. So the real issue is given its current model, in order for ChatGPT to come up with something that appears novel (e.g. ask a novel question) there has to be a relatively strong relationship between the training dataset and the question. In other words, the invention basically has to be implied by its current training data.

A different perspective might be to ask, given the things that humanity has invented, was any invention truly novel, or have we just steadily fleshed out inventions that were implied by the current state of the art? If the answer is the latter, then it is conceivable that a LLM would be able to eventually come up with everything that humanity has ever created in time, but the model would have to consume more resources than anything currently available.