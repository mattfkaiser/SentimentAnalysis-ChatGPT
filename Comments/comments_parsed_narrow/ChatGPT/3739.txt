Can't believe I'm not seeing this at the top:  


ChatGPT IS NOT BUILT TO BE CORRECT AT THINGS  


  
It's built to sound plausible. Much of the time it *will* be correct, much like sometimes a psychologist can be wrong sometimes. But good lord why are you entrusting your daughter's mental health to a literal unfeeling machine when you can change psychologist if you're not happy with them?  


  
I'm not bashing ChatGPT here either, I use AI for my work daily in the form of GitHub's Copilot. Here's the difference though: I'm a professional in the field that the tool is helping with, so I can tell when it's wrong. You can't tell whether ChatGPT is wrong about advice it gives, and also likely you can't tell whether your daughter's psychologist is wrong about what theyr'e saying. Maybe they're right, maybe they're keep things confidential with their actual patient, you probably don't have the expertise to judge.