Technologies like ChatGPT, Bard, Bing Chat, etc...they all also rely on human knowledge/expertise/etc in order to synthesize human knowledge and intuition.  But without us as an input, AI risks feeding in AI output more regularly as we go forward.

A loose analogy for the effect that can have, is akin to recompressing an already compressed jpeg.  There is a risk of inaccuracies building upon inaccuracies, depending on how knowledge is sampled.  And it may become harder to verify knowledge if humans do what they typically do....copy paste from another source.  So even if we make sure AI points to human made knowledge, the potential influence and impact of AI and its shortcomings will still always be there going forward.  It can become especially rough if it puts enough of us out of work...as it's unclear how motivated we may be as a species to correct at the source what AI got wrong if we have to do it for free. It would require rediscovering knowledge that AI potentially causes us to lose.