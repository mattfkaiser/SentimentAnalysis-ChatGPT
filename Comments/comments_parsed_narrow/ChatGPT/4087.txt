As a lawyer, I agree with you and I can tell you that I tried to use the chatGPT and besides being a bit helpful sometimes for redacting a contract, it is pretty much a good search tool, nothing more.

1. It can't interpret the law. Let's remember that lawyers have to bend and force a law (nice way to say cheat, lie or confuse the listener) so it fits your client's interests. Persuasiveness, craftiness and trickery are not the exact things that chatGPT will excel at, since it is pretty much the opposite of giving a mathematical or true answer. It is not even about a point of view on a topic but straight bending the interpretation of things that are sometimes/usually borderline illegal.
2. It clearly fails to recognize obscure concepts even when given very decent prompts, as law is something that continually evolves and it can outpace AI in the sense of: Will the AI solve the use case of a newly released law? Sometimes yes, sometimes not. 
3. The fact that chatGPT can solve a lawyer's test doesn't mean much (it has a clear truth/answer that can be looked for in books), complex legal problems require not only the proper answer and knowledge but being able to ASK tons of questions to people that are sometimes straight dumb that don't even understand the answer they are providing and can contain accidental falsehoods.
4. The only way an AI would be superior to a great lawyer in court, would be if the judge was an AI as well, and that will never happen. What happens if someone is disabled and requires extra care? Will the AI ask something like "are you mentally impaired, or in the beginning stages of dementia?", i doubt it.