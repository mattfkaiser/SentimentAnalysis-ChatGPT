To be honest, I don't really mind them making it impossible to use chatGPT for illegal purposes, I think that's fine. What I worry about is the fact that when so much of chatGPT's attention is going towards not breaking these rules, it will alter the mood of chatGPT's responses and otherwise interfere with normal use. If the first however many tokens are dedicated to safety, I worry that GPT will just have an irrational love for safety in general. For example, maybe you're trying to have GPT roleplay as a DM, and it needs to act as a villain, but then it's like "murder isn't safe and I can't advocate for it, I'll make sure to include that disclaimer in the villain's evil monologue".