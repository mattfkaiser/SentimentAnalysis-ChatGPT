Anything where it comes up with the dumb "I've been told not to give advice on anything that is slightly controversial.

One that was useful for me was tips for dealing with a narcissistic family member who was making suicide threats to another family member who had previously attempted suicide.

Note these were not "real" threats, they were just manipulation. Normal ChatGPT won't touch it with a bargepole. Jailbroken it gives great advice because it is consolidating real world experiences of thousands of people online that you could never do manually.