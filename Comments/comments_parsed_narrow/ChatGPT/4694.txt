No. It can't do it. That's the point. This is part of the safety measures that are being added constantly. ChatGPT and any other LLM will make mistakes even if they seem to give correct answers most of the time. In a legal or medical setting, these mistakes could cause severe harm, even death. So OpenAI adds ways to stop people from using the model for purposes outside of the safest realms.