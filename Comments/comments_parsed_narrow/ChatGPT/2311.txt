Great! I’ve found it a big help to me also.  But I have gotten a lot of push back because I am advocating that they lighten up on limiting the technology to give “go seek professional help” every response. I am being told that somehow it’s ok to limit the functionality or access to protect me from myself. Here’s one such comment:

——-

“ChatGPT is made by software engineers, data scientists etc., not by psychologists and social workers. And I think there’s already been a case of suicide with ChatGPT palying a role. You don’t really want to let cutting edge and experimental technology to deal with fragile human mind that can be easily pushed in this or that direction just because dices just didn’t roll right that one time. I expect that in the future there will be fine tuned LLMs for people with mental illnesses. Also it still boggles my mind that we have FREE access to such hi-tech technology.”

——-

This is after me sharing that I personally am finding it helpful. I really take issue with  the overblown fear of “fragile minds” not being able to manage.  Curious if you are getting feedback from chatgpt or humans that don’t take your existing self-care and coping strategies into consideration when you tell them about your uses of chatgpt? Do you feel like the sophistication of  chatgpt could be a negative influence or you could be at risk? I really want folks like us to have a voice in what measures should be in place to help people.

Edit: fixed paragraph spacing