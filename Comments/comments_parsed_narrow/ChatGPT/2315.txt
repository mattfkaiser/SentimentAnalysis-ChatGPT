Part of me thinks that if this is indeed working for you, then great. What's the harm, right?

Part of me, though, is worried: what if, in an especially vulnerable situation, ChatGPT's output is inappropriate? It has happened. What if ChatGPT's chat logs get leaked to other users? That, too, has happened. What if the "research and information you need" is wholly made up and inaccurate? That has happened before.

This scenario, is at best, a crutch. It works because you believe that ChatGPT understands you and gives a shit. It cannot and it doesn't. There isn't actually any "it" that could do anything. Sure, you can't "call your therapist in the middle of the night, or several times a day," but if you feel you need that to get through the day, then maybe an AI isn't the best answer to your problems.

You're possibly growing dependent on something that, at any time, could be changed, limited, taken away, made cost-prohibitive and. Does. Not. Care. About. You. At. All.

All with great risk to your most intimate and private thoughts.