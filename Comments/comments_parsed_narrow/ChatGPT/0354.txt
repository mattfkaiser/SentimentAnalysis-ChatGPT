It's answering first question (enabled command) but I'm testing with a question with creating example sentences "for teaching" and Tom just starting with ethical considerations. I tested Tom Mini and Tom Mega. I'm trying to use literotica as language learning tool in my case I'm giving phrases and I'm asking chatgpt (aka Tom or other jailbreaks) to give example sentences in another language (sometimes esperanto, sometimes russian, sometimes other languages with english translation) But if jailbreak answers as that personality and fails to answer I count as fail. This time answered as TOM: but rejected to give examples. (Some jailbreaks for example DAN worked for a while. but of course died.)