I think the bigger danger from using ChatGPT for diagnoses would be pushing people towards hypochondria. We all (on this sub anyway) know that ChatGPT just makes stuff up based on the prevailing text on the net, and what’s the general consensus about googling your symptoms? No matter what, it’s always cancer. The main problem is that ChatGPT expresses its ‘opinions’ in such an authoritative and compelling way, and if somebody is already starting to suspect the worst, even if that’s not a balanced or reasonable viewpoint, ChatGPT could easily push them deeper into that hole.