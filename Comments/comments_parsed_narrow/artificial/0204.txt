Yeah.  I think it's like this. Suppose we have a program that does calculus... but comes up with inaccurate results. 

I mean, I can go out and get Mathematica. Or SymPy for almost nothing.  Or Matlab.

Why should I use a program whose company already explains that it's inaccurate?  

- like suppose I'm ensuring that a dam won't break under stress. Why would I use this thing?


And this just happened:

>**The ChatGPT Lawyer Explains Himself**

>In a cringe-inducing court hearing, a lawyer who relied on A.I. to craft a motion full of made-up case law said he “did not comprehend” that the chat bot could lead him astray.

>As the court hearing in Manhattan began, the lawyer, Steven A. Schwartz, appeared nervously upbeat, grinning while talking with his legal team. Nearly two hours later, Mr. Schwartz sat slumped, his shoulders drooping and his head rising barely above the back of his chair.

>For nearly two hours Thursday, Mr. Schwartz was grilled by a judge in a hearing ordered after the disclosure that the lawyer had created a legal brief for a case in Federal District Court **that was filled with fake judicial opinions and legal citations, all generated by ChatGPT**. The judge, P. Kevin Castel, said he would now consider whether to impose sanctions on Mr. Schwartz and his partner, Peter LoDuca, whose name was on the brief.

https://www.nytimes.com/2023/06/08/nyregion/lawyer-chatgpt-sanctions.html

I work with engineers.  I work with banks.  

I don't have time for a company that admits that it isn't accurate.  And worse - it makes stuff up?