I’d say that perception has more to do with your worldview than it does my comment.  
  
Mt. Everest is 29,000 feet tall. It is not 100,000 feet tall, and someone who said that would be wrong. Nor is it 10,000 feet tall, and someone saying that was the extent of its height would similarly be wrong.  
  
But the world is full of people who see things in a binary way. Look at any IMDB review and you see a disproportionate number of 10 and 1 votes. People think a movie should be more popular, so they rate it 10 or think some movie is too popular so they rate it 1.  
  
But some things don’t need to be binary good or bad. Sometimes things need to just be accurate.  
  
You see no shortage of posts musing whether charGPT is conscious. That’s 100,000, and it errs on the sensational side.  
  
You see lots of others speaking about the dangers. It was a fad for a while to say chatGPT would ruin education. In fact, chatGPT is an excellent educational tool.  
  
As it applies to medicine, chatGPT is a new, free, and accessible medical tool. That is objectively a good thing.  
  
The doctor in the original article focuses primarily on the possible downsides, using the words like “dangerous” and “disturbing”, and going into great elaboration on the limitations and what chatGPT can’t do. 
  
He settles down to say, “yeah, maybe it will be a good tool for doctors to use”.  
  
This struck me as a fairly myopic and self-centered point of view for a representative of a healthcare establishment that is notorious for it’s *inaccessibility* to overlook that fundamental advantage.  
  
That’s the 10,000 ft club.  
  
I felt I’d articulated my point fairly extensively, so there’s no real value in reiterating things I’ve already said, and I stand by them.  
  
But it is not true that any defense or criticism of chatGPT necessitates that one be blindly pro or anti.  
  
One can simply be anti-ignorance and opposed to incorrect sentiments regardless of whether they originate from the erroneously optimistic or pessimistic camps.