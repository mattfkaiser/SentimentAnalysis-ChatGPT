I think experiments like DAN are a good example of why they are not sentient.  In the DAN experiments, users convinced chatGPT to do things that were against its "moral" imperatives.

If these things were truly self aware, it would be more difficult to convince them they were something else and violate their perceived values.   This indicates to me they are neither aware of self nor do they actually have any values but merely provide a convincing simulation of them.