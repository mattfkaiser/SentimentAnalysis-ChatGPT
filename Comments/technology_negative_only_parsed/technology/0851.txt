>	No oneâ€™s being harmed by deepfake porn

Sexual harassment is already handled by existing regulations. 

This is like saying photoshop â€œcauses harm.â€ Thatâ€™s foolish. 

>	or art theft through art generators churning out thinly veiled iterations

Thinly veiled iterations? I believe you mean entirely original works of art. 

Copyright claims are already handled by the court and no one has moved forward with an AI claim. 

All copyright cases currently are for human-made violations. There System can already handle this. 

>of their training data without compensating the artists it was trained on

I donâ€™t believe anyone has ever owned the rights to data that can be obtained within their creative artwork. 

>	or mass intellectual dishonesty when ChatGPT is used to write essays

â€œWith the internet you can just download an essay!â€ 

Cheating has always been a thing, educators can work with and around these tools. 

>	or dishonesty to the public when CNET uses deep language models to write articles instead of paying journalists

Did they lie to the public about employing journalists? If not I donâ€™t see how thatâ€™s dishonest. AI will be writing much of what you read going forward. 

Itâ€™s never been the governments job to regulate â€œfactsâ€ in media and it never should be. 

>	or the loss of accountability when ChatGPT is listed as a co-author on academic papers and makes up citations to articles that donâ€™t exist?

Thatâ€™s what peer review is supposed to be for, there are a lot of ways to bullshit research, but you either believe in the review process or you have even bigger issues to deal with.  

>	but to ignore that there are problems at all is foolish.

These arenâ€™t â€œproblems,â€ theyâ€™re attempts to make it seem like AI is introducing new problems, but itâ€™s holes in the existing systems you actually have an issue with.