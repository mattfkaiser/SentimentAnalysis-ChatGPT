There may actually be a clinical reason for answers that seem "shallow."For example, the psychologist might actually see that what your daughter needs is not advice (therapists usually do not give advice, and you should not be taking advice, they should be leading you to make your own conclusions), but someone to listen and understand who is NOT involved in her life in other ways (as a parent, as a friend) because they can trust the psychologist's ear not to be biased by that kind of relationship.

The psychologist may be giving shallow answers to allow the butterfly its necessary struggle, so to speak, gently allowing her to work through her own problems so that she builds confidence in her ability to tackler similar conflicts in the future, acting as a basically inert support, where just *being there* is enough to give your daughter the confidence to tackle that struggle.

Without context, we really can't say, but there are many explanations for chatGPT seeming more credible while being absolutely inferior, which is itself a problem of chatGPT. It's only reacting to the tiny amount of information that you're telling it, not the innumerable data points that human naturally absorb from other humans, social beings that we are. It has less context than I'm working with, less of an ability to guess like I can.

ChatGPT can't really evaluate and understand the social, family, individual dynamic like a person can do within minutes of feeling out a room and the people in it, and I don't think it's going to do more than make secretaries more efficient at administering preliminary screening. Don't ditch your psychologist without having a discussion with that psychologist