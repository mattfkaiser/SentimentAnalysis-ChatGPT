I was just worrying about factual content being blended with falsehood by accident because people will produce articles etc using chatGPT without fact checking. Since this is now incredibly easy and quick to do, more and more articles will be produced like that. Overtime, further models will start to use those fasle articles as training material and unwitting humans will reinforce the false content and the cycle will repeat and strengthen. Eventually, search engines will be basically useless due to the sheer amount of "close" but false information.