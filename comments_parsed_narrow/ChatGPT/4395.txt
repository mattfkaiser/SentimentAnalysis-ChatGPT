> I appreciate your perspective on this so I am wondering how you see tools like ChatGPT and our path to AGI?

Smoke and mirrors that make it seem like we're much closer than we actually are to AGI. They *seem* like a huge leap because we aren't used to programs that can deliver information using seemingly original English syntax, grammar, and paragraph structure. They also fit another criterion that I think people sort of innately believe to be true about AGI, which is that we will not actually understand how it works in any given instance. I don't say this to say they aren't a significant development.

ChatGPT and tools like it, in themselves, are a huge accomplishment. It can be incredibly useful for many things, including helping form communications of your own thoughts to other people. It can be an incredibly powerful tool, is extremely capable of abuse and almost certainly will be abused. It isn't AGI or anywhere close at this point in time, but just a few nefarious things I can imagine tools like this doing extremely successfully (with some modification but perhaps not much): start multi-level marketing schemes, run scam calls to the elderly requesting money, impersonate a large volume of political activists on the internet to influence the outcome of elections or social movements. The tools, as they currently exist, will be exceptionally dangerous even without being AGI. 

I don't know exactly what shape the solution to the AGI problem will take, or if we will last long enough to see a solution to that problem. My suspicion is that we won't see it until we build a computer so powerful that it can basically just simulate an actual human brain, and I think we're a reasonably long way from that point (could be decades, could be centuriesâ€”so a flash on an evolutionary timescale, if it happens, but a long way away in human lifespans).