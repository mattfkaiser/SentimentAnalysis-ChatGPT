Actually they are worried about the fact that ChatGPT is subject to the same pervasive biases as the humans that programmed and trained it. Its ability to crunch massive amounts of data and information is great.  But they are also worried that it's also a meta-echo chamber on steroids, capable of the kind of deception and hidden "motives" found in people.

In the end, they are concerned about the unpredictability and the lack of transparency of the answers ChatGPT can produce and how it will be used if put in the wrong hands.

ETA:  to add "lack of" in front of transparency to remove any ambiguity