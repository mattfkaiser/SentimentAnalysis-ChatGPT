Agree. If the citations are not "pre-qualified" it may be difficult to trust. That's why "ChatGPT for your data" (as we do at [vectara](https://vectara.com)) is an interesting approach since your data is something you can control and qualify to be correct / trust-worthy. It clearly doesn't solve the broader problem of pure ChatGPT, but for the many use cases of "chat with your data" it's quite useful. 
In that context - I like your thinking about "how do I discern between reliable sources vs unreliable sources" - not an easy problem to solve. In the past journalism used to represent "a source you can trust", but I don't think that is true anymore (unfortunately).