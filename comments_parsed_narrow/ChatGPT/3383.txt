A lot of people here assuming it’s easy to retool curricula and/or downplaying all the extra effort that would go into new forms of evaluating student performance.
Also, a lot of people using the calculator analogy, as if all learning followed this model of calculative thinking.
As well, a lot of people assuming that writing a paper is just regurgitation of facts. Or a waste of time.
I teach in the humanities. There’s a lot of paper writing in the humanities, whether it’s history, political theory, English, philosophy, religious studies, etc. The kind of learning we hope to foster in these disciplines involves a good deal of critical analysis - reflecting on the material as well as upon one’s relationship to that material -, understanding and thinking through a position that an author takes, spending time looking at the world from an author’s viewpoint, developing one’s own position on an issue (ethical or otherwise), finding one’s voice (also one’s own position and the special kind of problem solving that this entails) through the process of writing, engaging in dialogue with others regarding a specific topic, formulating strong arguments, among other things. I take these all to be life skills, especially if someone is looking to avoid being manipulated by others. 

While chatGPT may help modestly with some of these skills, I find it to be largely a hindrance to their development. Perhaps it’s just me, but I think that articulating your own thoughts on a subject as well as the ability to effectively evaluate differing viewpoints, especially those that one disagrees with, are invaluable aspects to forming a robust self. And as crazy as that sounds, by and large nowhere else will you find a better place to develop these things than in college. 

Lastly, I embraced the humanities and teaching in them as a deeply meaningful pursuit. Yet what could be more meaningless than evaluating papers composed by a bot?