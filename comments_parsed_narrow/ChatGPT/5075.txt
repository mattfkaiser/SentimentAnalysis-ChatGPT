There is a way to use chatgpt to filter useful information. In the API guide it called embeddings search. You can take a huuuge text (up to 250 000 tokens, but there is no real limit 250 000 is just a limit per hour for embefdings) separate it into pieces lets say 512 tokens each and request openai for the vector representation. You will get numbers for each piece of text which represent semantic meaning of the text. You can compare them with vectors from your question and get parts of the text including only relevant information. So you dont exceed limits of chatgpt. It sounds complex, but just search for examples. It is easy to implement with python.

I implemented it in my bot. It works like a charm. I am using it to go through large books and search for information there. I attached more than 1000 pages of text and it works as fast as chatgpt, as soon as most of the processing is done inside of your PC and not at openai site.