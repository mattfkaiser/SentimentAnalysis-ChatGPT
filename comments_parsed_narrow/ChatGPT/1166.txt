personally found that chatgpt is useful in generating boilerplate stuff using mostly core language features for things I already know how they work (so if it makes a mistake I can either re-prompt it or fix it myself) but pretty much whenever I try to involve something that isn't industry standard with 10+ years of online examples to train on and very stable API, or a prompt that covers more than one usecase, it tends to mess up. and if it's a language or library I don't know very well it can easily take me more time to figure out what it messed up than to read the docs and write it from scratch.

coding assistant LLMs like copilot and starcoder no doubt work a bit better on average since they base their suggestions on code already written rather than generating something from nothing.