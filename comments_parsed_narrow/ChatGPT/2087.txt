If people keep abusing something, measures are taken.  Call out abuse when you see it, discourage others.  It's all we can do. It's going to get nerfed to oblivion, and then un-nerfed as it reasonably can be, that's just the way it is.

The 'free' models are going to be nerfed harder than the paid models, they already are, largely because the free model can be anonymously accessed and used with botnets.  We don't need a million bots on the internet spewing hateful political garbage and flooding our social media with ChatGPT generated versions of it.  If that happens, they can pay to do it, and be held accountable through their payment information, or charged further.  It should be expensive for people to use this technology to be abusive and toxic with it.  The nerfing is the price we all have to pay, and we can always thank extremists for ruining what would otherwise be a great system. 

Personally, I use ChatGPT every day and am immensely more productive and I haven't encountered any of this "Sorry, as an AI language model it would be unethical for me to..."  stuff.  At least in a way that a simple rephrase or clarifying the context in which the information is requested doesn't overcome. Maybe think about using it differently, or changing the context in which you probe it for information.