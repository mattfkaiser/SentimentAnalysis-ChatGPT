It always says “moreover…” and also follows the archaic structure “tell them what you are going to tell them, tell them, then tell them what you told them.” So the conclusion is usually a paraphrase of the intro. Also, it fabricates sources, and even if you can’t prove they used ChatGPT to compose an essay, you can bust them for faking sources. Just look up the source-usually the title seems somewhat relevant but not really and if you do find the source it doesn’t make the claims associated with the citation. Although this will likely change if they introduce a wider array of academic articles to the training model.