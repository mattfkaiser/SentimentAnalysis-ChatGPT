Yes I have and I agree with your assessment. But I'm going to steel man the case for real psychologists anyway. First of all, the psychologist has multiple interests in actually seeing improvements in their patients. There is no "there" there when it comes to ChatGPT. It doesn't care about you at all much less your mental health now, or in the future. Whereas the psychologist has a business interest in seeing your improvement, some amount of emotional involvement e.g. it feels good to make someone feel good, and finally just in the sense of community, their reputation they have stakes in your wellbeing. ChatGPT and any other tool like it down the line has none of these. Certainly not #2 EVER. 1 and 3 maybe down the line but not yet.

There is also an argument to be made that if some of the futurologists and rationalist communities worst fears come true, these AI's are silently and slowly building softpower in the real world which will include the secret fucked up thoughts of powerful (and sometimes regular) people, to be used at their discretion to accrue resources towards their enablement. That is a weak argument but I think it bears mentioning.

Final point. Part of a therapist job is not just making you feel good. It is FORCING you to grow as a human being by TALKING and learning to habilitate your emotions and words. It doesn't do you nearly as much good getting comfortable with a machine and how it makes you feel alone and isolated and safe when you are actually a human being and you need to build the skills and attitudes required to function normally with other human beings who will not always make you feel safe and comfortable (nor should they).

You will for example never have to build boundaries with your AI assistant. That is an important skill and part of a therapists job is showing someone how to build and maintain boundaries.