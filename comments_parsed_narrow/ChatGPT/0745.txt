> itâ€™s main weaknesses would probably boil down to bot farming and bias from users

Unfortunately, yes. But like many things out there, it's the best bad system we currently have. Ha!

I also would have thought the GPT models might weaken over time due to bias, but the blind aspect of it means you can't actually (necessarily) tell when you're getting a GPT response.... though from personal experience it's usually quite obvious when you get a GPT4 or Claude response, as they're often noticeably better and many of the OS models being indexed are weak in similar ways to each other. It's obvious that user bias is going to come into play, but the idea is that a broad spectrum of bias's will eventually even out. 

My personal suspicion is the uncensored models (most of which are Open Source (OS), though the research version of several of the Closed Source (CS) models interfacing with the Arena are actually uncensored/less-censored despite the commercial APIs not having the same freedom) have a slight bias in their favor, as some subset of users are making content filtered requests and punishing models that give a boilerplate refusal... but even that bias doesn't appear to be huge, as the highest ranked uncensored model in the latest leaderboard release only got a 1054 elo, but when the next leaderboard comes out in a few weeks with WizardLM being indexed as well, we'll see if an uncensored bias persists (and Snoozy is only semi-censored, since it only inherited OpenAI censoring by virtue of being trained on GPT4 outputs, so it's laughably easy to jailbreak). My prediction is we will see the Guanaco-65b either beating or coming extremely close to ChatGPT in the next leaderboard, and if it doesn't beat it, I would bet Falcon-40b will once it gets added to the Arena (I think the new h20 version of Falcon-40b will run fast enough to get listed, though I have no idea if it's been requested yet, as it's the current leader on the Huggingface rankings. You can test out a version of the Falcon-40b model [here](https://gpt-gm.h2o.ai/) and let me know what you think, though you'll have to make sure you change the default settings or that interface will have you talking to the weaker 7b parameter Falcon model.)

The Falcon-40b is one of the beefiest OS models (though Guanaco-65b is competing for that position as well), which if I recall correctly needs something like 60GBs of VRAM to run. Not achievable for most of the public, but still orders of magnitude more efficient than even the current nerfed version of ChatGPT that OpenAI is hosting for free to the public. There's a nerfed 7b version of Falcon that's been ported to the GPT4all ecosystem, but it underperforms relative to Hermes and Snoozy, which is why I haven't downloaded it myself. I'm getting really tempted to dump a bunch of money into a bigger rig, but I think the smart thing is to just be patient. (though I did just order 16GBs more SODIMM RAM yesterday to "max out" (kinda, not really) my current capacity... heh heh...)

:(

Anyway, thanks for chatting about this! I love talking about the Open Source community. It's developing so fucking fast right now it's almost hard to keep up. I stopped following the latest news for, like, 2 or 3 months and they went from being impossible to run on my rig to being laughably easy to run literally dozens of models AND they're producing way more useful responses than they were the last time I tried them out.

I'm most excited to see how Deepmind's Tree of Thought prompt engineering program could be applied to these OS models to further improve performance, but it's probably going to be a few months before someone more savvy than me does the hard work of implementing that in a robust way, and I can't be assed to do it myself. If you're interested, [here's the paper](https://arxiv.org/abs/2305.10601) and you can download the github if you want to tinker with it (though it looked to me like they only wrote the program to run on three highly specific problems, so I'm not sure how generalizable it will be at the current level of development).