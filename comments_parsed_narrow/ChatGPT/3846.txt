It is. Because it is a "stochastic talking parrot", as you put it, it's not really considering only information from 1800. The "parrot" has been trained on the modern internet, and you can't change that. That's why it can talk about things invented after the 1800s - because it has been trained on plenty of data that included information about things that happened after the 1800s.

Incidentally, this is also why it replies, even in this instance, in modern English and not in an 1800 vernacular. If you truly took a neural network similar to chat GPT and trained it ONLY on source material from or before 1800, you would have a better experiment of the sort you are proposing. And since chat GPT isn't really "thinking" in the way we do, only extrapolating from what it's has been trained on, we can't really expect it to come up with whole new concepts, like calculus.

That's why none of these generative text models have come up with anything remotely approaching genuinely new thought - like an internally consistent new physical theory, or some new kind of math, like calculus. This is despite being trained on everything you can find on the internet - everything from zoological charts to string theory - and having had lots of opportunities by this point to prove its abilities in such an arena.