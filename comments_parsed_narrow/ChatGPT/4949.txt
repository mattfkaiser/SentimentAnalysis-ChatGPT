Either they're not following the rules or they're using their search that has already stored the data from the page? I'm not 100 percent on how it works, I only have experience using webscrapes for my own python projects for finding local investment opportunities. But even the smaller companies just have a default robot.txt that basically says don't scrape. I'm assuming all the questions asked to ChatGPT will be similar in nature (since a lot of people all want to know the same things). So, might end up essentially ddosing the websites most used for that data? Costly to upkeep a server that's used that consistently and no one is viewing the adverts since it's just a bot browsing.