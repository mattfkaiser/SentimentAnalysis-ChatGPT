A calculator automates the task of storing information in working memory.  Working memory tends to have a limited capacity and does not ‘improve’ with practice.  So, it’s OK to augment that memory limitation with tech with minimal pedagogical downside.  As we see in academia, professors might allow simple calculators to be used during testing to support speed of processing but still require students to demonstrate depth of processing (the extent to which they learned the procedure) by writing down the steps to the answer (“showing their work”).

In contrast, ChatGPT automates the task of deep information processing, which is critical for forming long term memories, and ultimately acquiring expertise in both topics as well ask the skill of synthesizing, interpreting, and drawing connections between different information sources.

Clarity of writing is a measure clarity of thought. Universities - and all schools for that matter - are rightly worried that ChatGPT presents serious risks to the goal of education: creating expert critical thinkers.

I work in Tech with a large amount of PhDs, and even in that crowd of highly trained writers, it’s easy to tell who has endured more rigorous writing curriculums and who has endured less.  They each have a degree that signals domain expertise in their field, but the ones that learned to write are on a different level in their thinking and can solve much more complex problems with much greater ease.