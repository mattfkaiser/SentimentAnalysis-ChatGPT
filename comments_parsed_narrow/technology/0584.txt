Guy deserves the flak for not double checking the output, but I think the buzz around ChatGPT is somewhat to blame. A lot of people really don’t seem to understand that it’s just an in credibly sophisticated language model, it predicts what a string of text is supposed to look like based on what you input. It’s not going to replace all thinking for you. It can spit out a very generalized body of text that’s probably 90% of what you’re after, but it’s still up to you to fill in that remaining 10%.