Esos and hype definitely blew it out of proportion, but your analogy is missing some aspects. chatGPT won't say "idk" and it's not just having trouble sifting through information correctly. It fabricated things. It told me a documentary existed, which was done by a specific director, in a specific year, with a specific title, and that documentary in fact, doesn't at all exist. And things like that. Idk how exactly it works, but it fabricates information. Maybe it is just finding some fabrication some person made, and is parroting it, but afaict, that's not the case in my experience given the answers it gave, and how it gave them/how I had to ask it for the information