I've been surprised by the lack of controversial content from chatgpt given past results from things like Microsoft's Tay. They're probably censoring a lot of things beyond what we might broadly agree is toxic. Questions about which country controls certain territory, factual questions about religious figures, or anything casting doubt on the legitimacy of monarchies would all cause trouble for the global businesses releasing these bots. They also have to be concerned about libel when discussing public figures.