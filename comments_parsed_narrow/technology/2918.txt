I’ve talked to people who use cheat checker algorithms on programming projects and from the way they described it they don’t get a binary “yes or no” back but rather a confidence interval. Then they’ll review the top 10 “cheating” submissions and manually review them. That way people aren’t just at the mercy of an algorithm.

Applying this to chat GPT I could see people using these algorithms and then bringing in the suspected cheaters for an oral exam.