>	No one’s being harmed by deepfake porn

Sexual harassment is already handled by existing regulations. 

This is like saying photoshop “causes harm.” That’s foolish. 

>	or art theft through art generators churning out thinly veiled iterations

Thinly veiled iterations? I believe you mean entirely original works of art. 

Copyright claims are already handled by the court and no one has moved forward with an AI claim. 

All copyright cases currently are for human-made violations. There System can already handle this. 

>of their training data without compensating the artists it was trained on

I don’t believe anyone has ever owned the rights to data that can be obtained within their creative artwork. 

>	or mass intellectual dishonesty when ChatGPT is used to write essays

“With the internet you can just download an essay!” 

Cheating has always been a thing, educators can work with and around these tools. 

>	or dishonesty to the public when CNET uses deep language models to write articles instead of paying journalists

Did they lie to the public about employing journalists? If not I don’t see how that’s dishonest. AI will be writing much of what you read going forward. 

It’s never been the governments job to regulate “facts” in media and it never should be. 

>	or the loss of accountability when ChatGPT is listed as a co-author on academic papers and makes up citations to articles that don’t exist?

That’s what peer review is supposed to be for, there are a lot of ways to bullshit research, but you either believe in the review process or you have even bigger issues to deal with.  

>	but to ignore that there are problems at all is foolish.

These aren’t “problems,” they’re attempts to make it seem like AI is introducing new problems, but it’s holes in the existing systems you actually have an issue with.