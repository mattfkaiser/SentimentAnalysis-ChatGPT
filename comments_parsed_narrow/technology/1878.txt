First thing, Bing is not the same as ChatGPT. They use ChatGPT, but there's some more complex stuff going on behind the scenes to integrate it with Bing. This is a major difference because ChatGPT has no access to the internet, and has no way of checking the factualness of what it or anyone else says. Bing on the other hand has been designed to perform searches, and those search results seem to be fed back into it with the original user query. So it's not learning from them so much as it's using the search results as a sort of prompt for a sentence completion algorithm (all ChatGPT really is). Actually learning in real time would be an incredibly complicated problem. For one thing they use a currated dataset for training, they'd have to filter all information before they can train with it. Then there's the technical challenges, training these models is incredibly computationally expensive, and can take weeks running on large compute clusters. If you want to update models by adding new data you need to loop over all the data (old and new) several times, otherwise the model risks "forgetting" some of the data, and not learning from the new data. There's also potentially thousands of people interacting with the models right now, even if you were trying to train on just new data it would be a mess to coordinate.

Long story short, it doesn't learn in the technical sense, though it may appear to in the same way it may give convincing BS on something the underlying model wasn't trained on.