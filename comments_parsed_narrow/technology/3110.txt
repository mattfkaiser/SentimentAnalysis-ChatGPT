I half-agree with your points. We certainly don't want to conflate bad actors' use of a tool with innate traits _of_ a tool, and we don't want over-regulation that inhibits using technology to reduce human labor and enable creative expression.

However, technology is also not politically neutral. A tool's design predisposes it towards certain applications, or requires particular contexts to exist. As an example, large language- and large image-models currently require an enormous wealth of training data and computational resources to create. We can all _use_ ChatGPT and Dall-E, but only well-resourced corporations like OpenAI and IBM are able to create them in the first place. It would be a mistake to treat such technologies as an inevitability, or to deploy them without _some_ consideration of their impact.

I completely agree with you regarding copyrighting artistic styles or concepts: I think copyright is a grossly misapplied tool, and it should not be used to constrain human innovation and creativity. You are mistaken if you interpreted my post as "we should ban AI or broaden copyright to prevent infringement of artists' rights." However, tools like Dall-E _do_ undercut the current funding structure for most artists, and make art-as-a-career even more financially unappealing than it was. If we want to foster the continued development of non-AI art, I think we need a significantly different funding structure for art, like a larger emphasis on commissions, or increased availability of grants, or universal basic income.

Similarly, AI _does_ offer "amazing opportunities to reduce [human drudgery]," but this is only a good thing if it improves the welfare of humankind. When we automate factory labor, do we offer paths to re-train the workers we've eliminated, or offer solutions like UBI to reduce the need for every human to have a job? Or are we putting those people on the streets because their employers have learned how to cut their workforce and redirect those wages into increased profit margins?

I hope this adds a little more nuance than describing AI development as a universally "good" or "bad" thing. As you say, AI and machine learning are going to be transformative technologies, and it's up to us to steer that transformation in a positive direction.