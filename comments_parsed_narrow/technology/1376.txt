Exactly. It's reflecting as some manipulative double-downer who can never be wrong. It'll will reflect as something else in the very next conversation it has. It's not actually feeling any of it in fact it's not even an artificial conscious like in movies. So even if someone wants to argue that an artificial conscious could somehow feel, it won't apply to ChatGPT regardless lmao. 

It's a language model.