There will always be a factor of error involved in everything. There will always be doctors who for their own agenda do not provide sound medical advice. There will always be mistakes, for 100s of years people believed the earth was flat. Malpractice insurance exists for a reason. 

I think what we see between WebMD and Chat GPT is different. On the surface they both represent the concept of medical information. WebMD is more accepted standardized knowledge while Chat GPT is more implied and summarized (and sometimes incorrectly)

AI is going to get better at this, and it's value proposition compared to WebMD is going to increase. It will get more accurate, better with results etc but to do that it needs to start somewhere, just like science and more specifically technology it general improves over time. 

WebMD has the benefit at the moment that it is more likely to be peer reviewed. But if it itself is not a doctor then what trust should we put into it, should we trust it 30% of the time or 50% or is the failing of trust not because it is not trustworthy but because we should not trust ourselves to interpret the information. I think that is the more like scenario and it's failing. 

Would I take medical advice from Chat GPT, potentially yes but within a very limit context and I would double check. Same thing I would do with WebMD. Currently I would trust a doctor a lot more than either, and I don't trust doctors 100%.