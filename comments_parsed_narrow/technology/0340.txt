I’ve had both moments of “holy fuck, this is the future” and “how can you be so stupid” while asking ChatGPT to write code; sometimes, it’ll nail it first try based off a one sentence explanation, and even if that’s not the case I can usually coax it into getting it right by pointing out mistakes. Other times, though, it’ll outright ignore specific directions, return cartoonishly wrong code, or my favorite one, give an explanation for the code that directly contradicts the actual program