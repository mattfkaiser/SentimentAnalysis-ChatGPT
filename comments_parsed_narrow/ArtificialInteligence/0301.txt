My first interaction with ChatGPT was to ask it about Matthew 20, a passage left out of explanations regarding what Jesus said about heaven because he directly answers the question saying we have to build it first. Like pedophile priests, the AI insists that it shouldn't be taken literally and means something completely different while not addressing why it was purposely left out in the first place.  


Then I asked it how German cloning expert Hans Spemann died in 1941. At first ChatGPT said a heart attack, but when I asked it where it learned that information, it quickly changed its answer and said that upon further review it was instead a stroke. Then it wouldn't work when I asked where it learned of the stroke.