ChatGPT doesn't understand simple logic; it doesn't know how to solve problems because it doesn't understand them. All it does is process existing knowledge and present it in a natural-sounding way. Like a newsreader on TV it has absolutely no idea what it's talking about.

Don't take my word or anyone elses though. Try it yourself. Present a simple problem so obvious that no existing research answers it directly. Like how much cheese you would need to stop a bullet fired from a handgun. No amount of logical reasoning would make it understand that a gun with an effective range of 50 meters can not penetrate a 5km block of cheese.